{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PeopleV3.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "PZa269MpxjF1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandas import Series,DataFrame\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix \n",
        "\n",
        "#ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "\n",
        "#Visualization\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as pylab\n",
        "import seaborn as sns\n",
        "#Configure Visualization Defaults\n",
        "#%matplotlib inline = show plots in Jupyter Notebook browser\n",
        "mpl.style.use('ggplot')\n",
        "sns.set_style('white')\n",
        "pylab.rcParams['figure.figsize'] = 12,8\n",
        "%matplotlib inline\n",
        "\n",
        "# Algorithms\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,ExtraTreesClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import xgboost as xgb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_oClLsmrxaFk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predictListingType(test_df):\n",
        "  test_df = test_df.drop(['Unnamed: 0', 'GUID'], axis=1)\n",
        "  \n",
        "  test_null = pd.DataFrame(data= test_df.isnull().sum()/len(test_df)*100, \n",
        "                    columns=['Percentage of Values Missing'],\n",
        "                    index=test_df.columns\n",
        "                   ).reset_index()\n",
        "\n",
        "  test_null['Percentage of Values Missing'].mean()\n",
        "  ## Caution - Only 50% percentile missing values are taken.\n",
        "  Notorious_test_null = test_null[test_null['Percentage of Values Missing'] > test_null['Percentage of Values Missing'].mean()]\n",
        "  test_null_drop = test_null[test_null['Percentage of Values Missing'] > 85]\n",
        "\n",
        "  test_col_to_drop = []\n",
        "  for test_cols in list(test_null_drop['index'].values):\n",
        "      test_col_to_drop.append(test_cols)\n",
        "  \n",
        "  test_df.drop(test_col_to_drop, axis=1, inplace=True)\n",
        "  test_df[\"Rating\"].fillna(test_df[\"Rating\"].median(), inplace=True)\n",
        "\n",
        "  # convert from float to int\n",
        "  test_df['Rating'] = test_df['Rating'].astype(int)\n",
        "  \n",
        "  \n",
        "  test_df.Rating.loc[ (test_df.Rating <= 67282) ]= 0\n",
        "  test_df.Rating.loc[ (test_df.Rating > 67282) & (test_df.Rating <=  69475) ]= 1\n",
        "  test_df.Rating.loc[ (test_df.Rating > 69475) & (test_df.Rating <= 71661) ]= 2\n",
        "  test_df.Rating.loc[ (test_df.Rating > 71661) ]= 3\n",
        "  \n",
        "  \n",
        "  test_df = test_df.dropna(subset=['Number_of_Reviews'])\n",
        "  # convert from float to int\n",
        "  test_df['Number_of_Reviews'] = test_df['Number_of_Reviews'].astype(int)\n",
        "  \n",
        "  test_df.Number_of_Reviews.loc[ (test_df.Number_of_Reviews <= 4) ]= 0\n",
        "  test_df.Number_of_Reviews.loc[ (test_df.Number_of_Reviews > 4) ]= 1\n",
        "  \n",
        "  \n",
        "  test_df[\"Host_Response_Rate\"].interpolate(method='linear', axis=0, inplace = True)\n",
        "  test_df = test_df.dropna(subset=['Host_Response_Rate'])\n",
        "  test_df['Host_Response_Rate'] = test_df['Host_Response_Rate'].astype(int)\n",
        "  \n",
        "  # Assign number to Host_Response_Rate limits\n",
        "  test_df.Host_Response_Rate.loc[ (test_df.Host_Response_Rate <= 25) ]= 0\n",
        "  test_df.Host_Response_Rate.loc[ (test_df.Host_Response_Rate > 25) & (test_df.Host_Response_Rate <=  50) ]= 1\n",
        "  test_df.Host_Response_Rate.loc[ (test_df.Host_Response_Rate > 50) & (test_df.Host_Response_Rate <=  75) ]= 2\n",
        "  test_df.Host_Response_Rate.loc[ (test_df.Host_Response_Rate > 75) ]= 3\n",
        "  \n",
        "  ##Extra_People\n",
        "  test_df['Extra_People'].fillna(0, inplace = True)\n",
        "  test_df['Extra_People'] = test_df['Extra_People'].astype(int)\n",
        "  test_df.Extra_People.loc[ (test_df.Extra_People <= 199.8) ]= 0\n",
        "  test_df.Extra_People.loc[ (test_df.Extra_People > 199.8) & (test_df.Extra_People <=  399.6) ]= 1\n",
        "  test_df.Extra_People.loc[ (test_df.Extra_People > 399.6) & (test_df.Extra_People <=  599.4) ]= 2\n",
        "  test_df.Extra_People.loc[ (test_df.Extra_People > 599.4) & (test_df.Extra_People <=  799.2) ]= 3\n",
        "  test_df.Extra_People.loc[ (test_df.Extra_People > 799.2) ]= 4\n",
        "  \n",
        "  ##Calculated_host_listings_count\n",
        "  test_df = test_df.drop(['Calculated_host_listings_count', 'Guests_Included'], axis=1)\n",
        "  test_df[\"Host_Total_Listings_Count\"].fillna(test_df[\"Host_Total_Listings_Count\"].median(), inplace=True)\n",
        "  test_df['Host_Total_Listings_Count'] = test_df['Host_Total_Listings_Count'].astype(int)\n",
        "  test_df.Host_Total_Listings_Count.loc[ (test_df.Host_Total_Listings_Count <= 557) ]= 0\n",
        "  test_df.Host_Total_Listings_Count.loc[ (test_df.Host_Total_Listings_Count > 557) ]= 1\n",
        "  \n",
        "  ##Availability 30.60.90\n",
        "  test_df = test_df.drop(['Availability_60'], axis=1)\n",
        "  test_df = test_df.drop(['Availability_90'], axis=1)\n",
        "  test_df.Availability_30.loc[ (test_df.Availability_30 <= 10) ]= 0\n",
        "  test_df.Availability_30.loc[ (test_df.Availability_30 > 10) & (test_df.Availability_30 <=  20) ]= 1\n",
        "  test_df.Availability_30.loc[ (test_df.Availability_30 > 20) ]= 2\n",
        "  \n",
        "  ##Availability 365\n",
        "  test_df.Availability_365.loc[ (test_df.Availability_365 <= 73) ]= 0\n",
        "  test_df.Availability_365.loc[ (test_df.Availability_365 > 73) & (test_df.Availability_365 <=  146) ]= 1\n",
        "  test_df.Availability_365.loc[ (test_df.Availability_365 > 146) & (test_df.Availability_365 <=  219) ]= 2\n",
        "  test_df.Availability_365.loc[ (test_df.Availability_365 > 219) & (test_df.Availability_365 <=  292) ]= 3\n",
        "  test_df.Availability_365.loc[ (test_df.Availability_365 > 292) ]= 4\n",
        "  \n",
        "  ##Minimum Nights\n",
        "  test_df.Minimum_Nights.loc[ (test_df.Minimum_Nights <= 5000.5) ]= 0\n",
        "  test_df.Minimum_Nights.loc[ (test_df.Minimum_Nights > 5000.5) ]= 1\n",
        "  \n",
        "  ##Maxi Nights\n",
        "  test_df.Maximum_Nights = pd.to_numeric(test_df.Maximum_Nights, errors='coerce')\n",
        "  test_df.Maximum_Nights.loc[ (test_df.Maximum_Nights <= 715827883.0) ]= 0\n",
        "  test_df.Maximum_Nights.loc[ (test_df.Maximum_Nights > 715827883.0) & (test_df.Maximum_Nights <=  1431655765.0) ]= 1\n",
        "  test_df.Maximum_Nights.loc[ (test_df.Maximum_Nights > 1431655765.0) ]= 2\n",
        "  \n",
        "  ##Bathrooms\n",
        "  test_df['Bathrooms'].fillna(1, inplace=True)\n",
        "  test_df['Bathrooms'] = test_df['Bathrooms'].astype(int)\n",
        "  \n",
        "  ##Room Type\n",
        "  test_df = pd.get_dummies(test_df,columns=['Room_Type'])\n",
        "  \n",
        "  ## Beds Bedsrooms\n",
        "  test_df['Beds'].fillna(1, inplace=True)\n",
        "  test_df['Bedrooms'].fillna(1, inplace=True)\n",
        "  test_df['Beds'] = test_df['Beds'].astype(int)\n",
        "  test_df.Beds.loc[ (test_df.Beds <= 6.333) ]= 0\n",
        "  test_df.Beds.loc[ (test_df.Beds > 6.333) & (test_df.Beds <=  12.667) ]= 1\n",
        "  test_df.Beds.loc[ (test_df.Beds > 12.667) ]= 2\n",
        "  \n",
        "  ## Cancellation Policy\n",
        "  # The main categories of Ticket are \"strict\", \"flexible\", \"moderate\".\n",
        "  # So I will combine \"strict\", \"strict_new\", \"super_strict_60\", \"super_strict_30\", \"super_strict_30_new\", \"super_strict_60_new\",\"long_term\" and \"no_refunds\" together.\n",
        "  test_df['Cancellation_Policy'] = test_df['Cancellation_Policy'].replace([\"strict_new\", \"super_strict_60\", \"super_strict_30\", \"super_strict_30_new\", \"super_strict_60_new\", \"no_refunds\"], \"strict\")\n",
        "  # Replace \"moderate_new\" by \"moderate\".\n",
        "  test_df['Cancellation_Policy'] = test_df['Cancellation_Policy'].replace([\"moderate_new\"], \"moderate\")\n",
        "  # Replace \"flexible_new\" by \"flexible\" \n",
        "  test_df['Cancellation_Policy'] = test_df['Cancellation_Policy'].replace([\"flexible_new\"], \"moderate\")\n",
        "  test_df = pd.get_dummies(test_df,columns=['Cancellation_Policy'])\n",
        "  \n",
        "  ##Experience offered\n",
        "  test_df = pd.get_dummies(test_df,columns=['Experiences_Offered'])\n",
        "  \n",
        "  ## Bed Type\n",
        "  test_df = pd.get_dummies(test_df,columns=['Bed_Type'])\n",
        "  \n",
        "  ## Amenities\n",
        "  test_df = test_df.dropna(subset=['Amenities'])\n",
        "  test_df = test_df.reset_index(drop = True)\n",
        "  test_df['Amenities'] = test_df['Amenities'].map(\n",
        "      lambda amns: \"|\".join([amn.replace(\"}\", \"\").replace(\"{\", \"\").replace('\"', \"\")\\\n",
        "                             for amn in amns.split(\",\")]))\n",
        "  np.concatenate(test_df['Amenities'].map(lambda amns: amns.split(\"|\")).values)\n",
        "  amenities = np.unique(np.concatenate(test_df['Amenities'].map(lambda amns: amns.split(\"|\")).values))\n",
        "  amenities_matrix = np.array([test_df['Amenities'].map(lambda amns: amn in amns).values for amn in amenities]\n",
        "  test_df['Amenities'].map(lambda amns: amns.split(\"|\")).head()\n",
        "  np.unique(np.concatenate(test_df['Amenities'].map(lambda amns: amns.split(\"|\"))))[1:]\n",
        "  amenities = np.unique(np.concatenate(test_df['Amenities'].map(lambda amns: amns.split(\"|\"))))[1:]\n",
        "  amenity_arr = np.array([test_df['Amenities'].map(lambda amns: amn in amns) for amn in amenities])\n",
        "  features = test_df[['Rating', 'Host_Response_Rate', 'Bathrooms', 'Bedrooms', 'Beds', 'Maximum_Nights', 'Minimum_Nights', 'Availability_30', 'Availability_365', 'Extra_People',\n",
        "                      'Room_Type_Entire home/apt', 'Room_Type_Private room', 'Room_Type_Shared room', 'Number_of_Reviews', 'Cancellation_Policy_flexible', 'Cancellation_Policy_moderate',\n",
        "                      'Cancellation_Policy_strict', 'Experiences_Offered_business', 'Experiences_Offered_family', 'Experiences_Offered_none', 'Experiences_Offered_romantic', \n",
        "                       'Experiences_Offered_social', 'Bed_Type_Airbed', 'Bed_Type_Couch', 'Bed_Type_Futon', 'Bed_Type_Pull-out Sofa', 'Bed_Type_Real Bed']]\n",
        "  \n",
        "  features = pd.concat([features, pd.DataFrame(data=amenity_arr.T, columns=amenities)], axis=1)\n",
        "  X_test = features\n",
        "  sc_X = StandardScaler()\n",
        "  X_test = sc_X.transform(X_test)\n",
        "  model_ = pickle.load(open(\".pickle.dat\",\"rb\"))\n",
        "  y_pred = model_.predict(X_test)\n",
        "  \n",
        "  #concatenate y_pred with test_df\n",
        "  \n",
        "return test_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i-jW7V7wx0Id",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  zf2 = zipfile.ZipFile('/content/gdrive/My Drive/PeopleInteractive/listings_test_send.zip')\n",
        "  test_df = pd.read_csv(zf2.open(\"listings_test_send.csv\"), sep=\";\") \n",
        "  output = predictListingType(test_df)\n",
        "  print(output)\n",
        "  output.to_csv(\"output.csv\", sep=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}